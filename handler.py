print("ğŸ¬ handler.py starting...")

import os
import torch
print(f"âœ… Python OK")

# ç’°å¢ƒå¤‰æ•°ç¢ºèª
HF_TOKEN = os.getenv("HF_TOKEN")
print(f"ğŸ”‘ HF_TOKEN: {'è¨­å®šæ¸ˆã¿' if HF_TOKEN else 'æœªè¨­å®š'}")

# CUDAç¢ºèª
print(f"ğŸ® CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"ğŸ® CUDA version: {torch.version.cuda}")
    print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")

device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "float32"

# WhisperXãƒ­ãƒ¼ãƒ‰ï¼ˆä¿®æ­£ç‰ˆï¼‰
print("ğŸ§  Loading WhisperX large-v3...")
import whisperx
try:
    model = whisperx.load_model(
        "large-v3",
        device=device,
        compute_type=compute_type,
        language="ja",
        asr_options={
            "multilingual": False,
            "max_new_tokens": None,
            "clip_timestamps": "0",
            "hallucination_silence_threshold": None
        }
    )
    print("âœ… WhisperX loaded successfully!")
except Exception as e:
    print(f"âŒ WhisperX load failed: {str(e)}")
    # ãã‚Œã§ã‚‚ç¶šè¡Œã—ã¦ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ
    model = None

# ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
if model:
    print("ğŸ”§ Loading alignment model...")
    try:
        align_model, align_metadata = whisperx.load_align_model(
            language_code="ja",
            device=device
        )
        print("âœ… Alignment model loaded successfully!")
    except Exception as e:
        print(f"âŒ Alignment load failed: {str(e)}")
        align_model = None

# Pyannoteãƒ­ãƒ¼ãƒ‰
print("ğŸ§ Loading pyannote diarization...")
try:
    from pyannote.audio import Pipeline
    diarize_model = Pipeline.from_pretrained(
        "pyannote/speaker-diarization-3.1",
        use_auth_token=HF_TOKEN
    )
    diarize_model.to(torch.device(device))
    print("âœ… Pyannote loaded successfully!")
except Exception as e:
    print(f"âŒ Pyannote load failed: {str(e)}")
    diarize_model = None

print("ğŸ”¥ MODEL LOADING TEST COMPLETE ğŸ”¥")

# RunPodèµ·å‹•
import runpod

def handler(job):
    return {
        "status": "model_test_complete",
        "whisperx": "loaded" if model else "failed",
        "alignment": "loaded" if align_model else "failed",
        "pyannote": "loaded" if diarize_model else "failed"
    }

print("ğŸš€ Starting RunPod handler...")
runpod.serverless.start({"handler": handler})
